{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Graph Analyzer \n",
    "### With image processing and pdf input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from opencv_alvin import *\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "doc = fitz.open(\"animals.pdf\")\n",
    "for i in range(len(doc)):\n",
    "    for img in doc.getPageImageList(i):\n",
    "        xref = img[0]\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        if pix.n < 5:       # this is GRAY or RGB\n",
    "            pix.writePNG(\"pdfImages/p%s-%s.png\" % (i, xref))\n",
    "        else:               # CMYK: convert to RGB first\n",
    "            pix1 = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            pix1.writePNG(\"p%s-%s.png\" % (i, xref))\n",
    "            pix1 = None\n",
    "        pix = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## http://code.activestate.com/recipes/580703-extract-images-of-a-pdf-optionally-by-page-using-p/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `After this all images are extracted within the pdfImages folder with proper numbering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('bar_graph_images/basic.png',0)\n",
    "#img = cv2.imread('mobile_phone/mobile_template.jpg',0)\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(img,None)\n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(img, kp)\n",
    "img_keyPoints = cv2.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "\n",
    "im(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(img,None)\n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(img, kp)\n",
    "# draw only keypoints location,not size and orientation\n",
    "img2 = cv2.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "im(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_test = cv2.imread('bar_graph_images/bar1.jpg',0)\n",
    "#img_test= cv2.imread('mobile_phone/mobile_in_hand.jpg',0)\n",
    "kp_test = orb.detect(img_test,None)\n",
    "# compute the descriptors with ORB\n",
    "kp_test, des_test = orb.compute(img_test, kp_test)\n",
    "img_test_keyPoints = cv2.drawKeypoints(img_test, kp_test, None, color=(0,255,0), flags=0)\n",
    "im(img_test_keyPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "# Match descriptors.\n",
    "matches = bf.match(des,des_test)\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "# Draw first 10 matches.\n",
    "img3 = cv2.drawMatches(img,kp,img_test,kp_test,matches[:10],None,flags=2)\n",
    "im(img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bar graph detection using contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_org = cv2.imread('bar_graph_images/bar1.jpg')\n",
    "img_gray=cv2.cvtColor(img_org,cv2.COLOR_BGR2GRAY)\n",
    "#ret,thres=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "#dilated_img=cv2.dilate(img,(5,5))\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "img=cv2.morphologyEx(img_gray,cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "im(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_edges=cv2.Canny(img,30,200)\n",
    "im(canny_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci,contour,hierarchy=cv2.findContours(canny_edges,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#final_cont_img=cv2.drawContours(img_org,contour,-1,(255,0,0),1)\n",
    "#im(final_cont_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "accuracy is : 0.0 11\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "disp=img_org\n",
    "tot_len=len(contour)\n",
    "for c in contour:\n",
    "    \n",
    "    accuracy=0.03*cv2.arcLength(c,True)\n",
    "    approx=cv2.approxPolyDP(c,accuracy,True)\n",
    "    if len(approx)==4:\n",
    "        count+=1\n",
    "        disp=cv2.drawContours(disp,[c],0,(255,0,0),2)\n",
    "    else:\n",
    "        disp=cv2.drawContours(disp,[c],0,(0,0,255),2)\n",
    "        print(len(approx))\n",
    "print(str(\"accuracy is : \")+str(count/tot_len)+str(\" \")+str(tot_len))\n",
    "im(disp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## harris corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "harris_corners=cv2.cornerHarris(img_gray,3,3,0.06)\n",
    "\n",
    "im(harris_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytesseract as pyt\n",
    "def remove_text(img):\n",
    "    h=img.shape[0]\n",
    "    boxes=pyt.image_to_boxes(img)\n",
    "    for b in boxes.splitlines():\n",
    "        b = b.split(' ')\n",
    "        charLen_x=int((int(b[3])-int(b[1]))*0.5)\n",
    "        charLen_y=int((int(b[4])-int(b[2]))*0.5)\n",
    "#         if charLen_x>50:\n",
    "#             continue\n",
    "        img = cv2.rectangle(img, (int(b[1])-charLen_x,h - int(b[2])+charLen_y), (int(b[3])+charLen_x, h - int(b[4])-charLen_y), (255, 255, 255), -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar2=cv2.imread('bar_graph_images/bar2.jpg')\n",
    "im(bar2)\n",
    "bar2_gray=cv2.cvtColor(bar2,cv2.COLOR_BGR2GRAY)\n",
    "bar2_gray=remove_text(bar2_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=np.ones((5,5),np.uint8)\n",
    "img=cv2.morphologyEx(bar2_gray,cv2.MORPH_CLOSE,kernel)\n",
    "im(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
